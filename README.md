# Тестовое Задание Fast Forward
## Техническое задание
Дан набор реальных биржевых данных (формат сообщений описан ниже). В
первой строчке находится снепшот стакана, далее следуют сообщения об
апдейтах.
Вам необходимо реализовать программу на языке C++, которая восстанавливает
снепшоты стаканов на каждый апдейт. В выходной файл необходимо вывести
цены и объемы лучших уровней best bid и best ask с временной меткой. Подумайте
над выбором оптимальной структуры данных для данной задачи, учитывая, что
максимальное количество ценовых уровней на одной стороне снепшота равно 20.
Подумайте, что нужно будет поменять, если размер одной стороны книги будет
больше - 400 уровней. Основное требование к решению - это его
производительность.
Дополнительно необходимо провести benchmark на скорость обновления стакана
и получения из него best bid и best ask. Проведите сравнение различных структур
данных для книги. Бенчмарк должен включать в себя только применения
распарешнного события к ордербуку, не нужно включать в него время парсинга и
время дискового чтения/записи.

## Пояснение к решению
Так как уровней всего 20, то скорее всего, решение основное на простом массиве будет самое эффективное,
так как ядро оптимально работая с последовательным участками памяти, несмотря на то что асимптотическая сложнасть самая неоптимильная

Для baseLine реализовал решение основанное на структуре map
Так же считаю, что структура Heap должна отлично подходить для решения задачи, потому что можно реализовать очень близко к массиву и при не очень большом количество изменений структуры, она должна побеждать.
Из общего интереса, хочу посмотреть как изменится время работы Map, если заменить его на хэш-табличку. Предполагаю что должно стать быстрее, но структура не оптимальна.
### Реализация
* Map: std::map
* Hash: std::unordered_map 
* Heap: Кастомная структура на основе std::vector, с поддержкой операций upsacle downscale для удаления и добавления элементов в HEAP
* Array: Использовал std::array с поддержкой удаления за O(1) 
### Асимптотика
* Map: 
  * Инициализация O(NlogN)
  * Апдейты O(LogN)
  * Получение топов O(1)
* Array: 
  * Инициализация O(N)
  * Апдейты O(N)
  * Получение топов O(1)
* Hash: 
  * Инициализация O(N),
  * Апдейты O(1),
  * Получение топов O(N) 
* Heap: 
  * Инициализация O(N) (так как входные вектора отсортированы)
  * Апдейты O(NlogN)
  * Получение топов O(1)
### Структура репозитория
Для парсинга Json использовал header only библеотеку https://github.com/nlohmann/json
Использовал идиомы PIMPL с++ языка, чтобы унести полностью реализацию в файлы. Засчёт этого я имею 
один общий класс и могу при линковке удобно подменять файл с реализацией структуры данных.
Все реализации структур данных можно найти в папке impl
## Бенчмарк
Для запуска бенчмарка можно воспользоваться скриптом ./run_test.sh 
Программа запускается 10 раз для каждой структуры данных
### Cтруктура вывода
Входные данный для программы берутся из файла /huobi_global_depth.log
Результат работы программы пишется в out_{DataStructure}
Время работы каждого запуска в result_time_{DataStructure}

### Конфигурация
Проводил замеры в следующей конфигурации:
CPU model: 11th Gen Intel(R) Core(TM) i7-11850H @ 2.50GHz
gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0

### Результат
Среднее время работы для каждой структуры. 
* Array: 6368   miliseconds
* Hash:  112421 miliseconds
* Heap:  11131  miliseconds
* Map:   18569  miliseconds 

В итоге простой массив показывает самый лучший результат. Интересно, что unordered_map работеат сильно хуже. Вероятно структура плохо оптимизирована для double ключа. 
При увеличение уровней с 20 до 400, результаты поменяются местами, Array думаю будет самый не оптимальный, думаю heap и map будут бороться за первое место по эффективности. В целом для heap очень многое зависит от типа данных, если будет не очень много удалений, а больше запросов топа и изменений значений, то он будет наиболее эффективным. 
 
